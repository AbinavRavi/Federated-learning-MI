{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "from syft.core.remote_dataloader import RemoteDataset\n",
    "from syft.core.remote_dataloader import RemoteDataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-stress",
   "metadata": {},
   "source": [
    "## Run client until end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_ptr = duet.store[\"meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RemoteDataset object on remote side\n",
    "rds_ptr = duet.syft.core.remote_dataloader.RemoteDataset(meta_ptr)\n",
    "# create RemoteDataLoader object on remote side\n",
    "rdl_ptr = duet.syft.core.remote_dataloader.RemoteDataLoader(rds_ptr, batch_size=32)\n",
    "# call create_dataset to create the real Dataset object on remote side\n",
    "rdl_ptr.load_dataset()\n",
    "# call create_dataloader to create the real DataLoader object on remote side\n",
    "rdl_ptr.create_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-promotion",
   "metadata": {},
   "source": [
    "### Create the Model in remote\n",
    "\n",
    "This model is the remote model and this has to be sent to the client site for training. Only disadvantage that I see is that the client must provide the computational resources for training a bigger model.\n",
    "\n",
    "While creating the module we must inherit from syft module and give a torch reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedMNISTModel(sy.Module):\n",
    "    \n",
    "    def __init__(self,torch_ref):\n",
    "        super(MedMNISTModel, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv_head = self.torch_ref.nn.Sequential(\n",
    "            self.torch_ref.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "            self.torch_ref.nn.ReLU(),\n",
    "            self.torch_ref.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            self.torch_ref.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            self.torch_ref.nn.ReLU(),\n",
    "            self.torch_ref.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            self.torch_ref.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),\n",
    "            self.torch_ref.nn.ReLU(),\n",
    "            self.torch_ref.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classification_head = self.torch_ref.nn.Sequential(\n",
    "            self.torch_ref.nn.Linear(in_features=2304, out_features=128),\n",
    "            self.torch_ref.nn.ReLU(),\n",
    "            self.torch_ref.nn.Linear(in_features=128, out_features=128),\n",
    "            self.torch_ref.nn.ReLU(),\n",
    "            self.torch_ref.nn.Linear(in_features=128, out_features=6),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_head(x)\n",
    "        \n",
    "        # Flattening\n",
    "        x = self.torch_ref.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.classification_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can create the model and pass in our local copy of torch\n",
    "local_model = MedMNISTModel(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = local_model.send(duet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cuda = False\n",
    "has_cuda_ptr = remote_torch.cuda.is_available()\n",
    "has_cuda = bool(has_cuda_ptr.get(\n",
    "    request_block=True,\n",
    "    reason=\"To run test and inference locally\",\n",
    "    timeout_secs=5,  # change to something slower\n",
    "))\n",
    "print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "# now we can set the seed\n",
    "remote_torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = remote_torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"Data Owner device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = remote_torch.optim.Adadelta(params, lr=args[\"lr\"])\n",
    "scheduler = remote_torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args[\"gamma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-resolution",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5)\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    if model.is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        return\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = torch_ref.nn.functional.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet.python.Float(0)  # create a remote Float we can use for summation\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            local_loss = None\n",
    "            local_loss = loss_item.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break\n",
    "        if args[\"dry_run\"]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local(model, torch_ref, test_loader, test_data_length):\n",
    "    # download remote model\n",
    "    if not model.is_local:\n",
    "        local_model = model.get(\n",
    "            request_block=True,\n",
    "            reason=\"test evaluation\",\n",
    "            timeout_secs=5\n",
    "        )\n",
    "    else:\n",
    "        local_model = model\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "    local_model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with torch_ref.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = local_model(data)\n",
    "            iter_loss = torch_ref.nn.functional.nll_loss(output, target, reduction=\"sum\").item()\n",
    "            test_loss = test_loss + iter_loss\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target).sum().item()\n",
    "            correct += total\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct / test_data_length\n",
    "    print(f\"Test Set Accuracy: {100 * accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-hybrid",
   "metadata": {},
   "source": [
    "## Dataloader remote transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torchvision = duet.torchvision\n",
    "\n",
    "transform_1 = remote_torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "transform_2 = remote_torchvision.transforms.Normalize(0.3, 0.3)  # this normalizes the dataset\n",
    "\n",
    "remote_list = duet.python.List()  # create a remote list to add the transforms to\n",
    "remote_list.append(transform_1)\n",
    "remote_list.append(transform_2)\n",
    "\n",
    "# compose our transforms\n",
    "transforms = remote_torchvision.transforms.Compose(remote_list)\n",
    "\n",
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "train_data_ptr = duet.syft.core.remote_dataloader.RemoteDataset(meta_ptr)\n",
    "train_loader_ptr = duet.syft.core.remote_dataloader.RemoteDataLoader(train_data_ptr, batch_size=32)\n",
    "#remote_torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)\n",
    "train_loader_ptr.load_dataset()\n",
    "# call create_dataloader to create the real DataLoader object on remote side\n",
    "train_loader_ptr.create_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_length(train_data_ptr):\n",
    "    train_data_length = len(train_data_ptr)\n",
    "    return train_data_length\n",
    "\n",
    "try:\n",
    "    if train_data_length is None:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "except NameError:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "\n",
    "print(f\"Training Dataset size is: {train_data_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-medicare",
   "metadata": {},
   "source": [
    "## Training call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args[\"dry_run\"] = False  # comment to do a full train\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    # remote training on model with remote_torch\n",
    "    train(model, remote_torch, train_loader_ptr, optimizer, epoch, args, train_data_length)\n",
    "    # local testing on model with local torch\n",
    "#     test_local(model, torch, test_loader, test_data_length)\n",
    "    scheduler.step()\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    if args[\"dry_run\"]:\n",
    "        break\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.get(\n",
    "        request_block=True,\n",
    "        reason=\"test evaluation\",\n",
    "        timeout_secs=5\n",
    "    ).save(\"./duet_mnist.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-regard",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image_and_label(image, label):\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth: {}\".format(label))\n",
    "    \n",
    "def prep_for_inference(image):\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    image_batch = image_batch * 1.0\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(image, model):\n",
    "    if not model.is_local:\n",
    "        print(\"model is remote try .get()\")\n",
    "        return -1, torch.Tensor([-1])\n",
    "    image_tensor = torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor)\n",
    "    preds = torch.exp(output)\n",
    "    local_y = preds\n",
    "    local_y = local_y.squeeze()\n",
    "    pos = local_y == max(local_y)\n",
    "    index = torch.nonzero(pos, as_tuple=False)\n",
    "    class_num = index.squeeze()\n",
    "    return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_remote(image, model):\n",
    "    if model.is_local:\n",
    "        print(\"model is local try .send()\")\n",
    "        return -1, remote_torch.Tensor([-1])\n",
    "    image_tensor_ptr = remote_torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor_ptr)\n",
    "    preds = remote_torch.exp(output)\n",
    "    preds_result = preds.get(\n",
    "        request_block=True,\n",
    "        reason=\"To see a real world example of inference\",\n",
    "        timeout_secs=10\n",
    "    )\n",
    "    if preds_result is None:\n",
    "        print(\"No permission to do inference, request again\")\n",
    "        return -1, torch.Tensor([-1])\n",
    "    else:\n",
    "        # now we have the local tensor we can use local torch\n",
    "        local_y = torch.Tensor(preds_result)\n",
    "        local_y = local_y.squeeze()\n",
    "        pos = local_y == max(local_y)\n",
    "        index = torch.nonzero(pos, as_tuple=False)\n",
    "        class_num = index.squeeze()\n",
    "        return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-porter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
